{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução das equações de Laplace ou Poisson por Métodos iterativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A equação de Poisson a duas dimensões espaciais toma a forma:\n",
    "$$\\frac{\\partial ^2 u}{\\partial x^2} + \\frac{\\partial ^2 u}{\\partial y^2} = f,$$\n",
    "\n",
    "em que $u$ representa o campo cujos valores queremos determinar em todo o domínio, e em que $f$ representa um termo fonte (ausente na equação de Laplace). No caso electrostático, representa cargas eléctricas. No caso gravítico representa massas. Pode ainda ser vista como estado estacionário para que tende a equação de difusão ou de calor, que veremos no próximo capítulo.\n",
    "\n",
    "Na sua forma discretizada, numa grelha rectangular de lados $\\Delta x$ e $\\Delta y$, a equação toma a forma:\n",
    "\n",
    "$$\\frac{u_{i+1,j}^{n}-2u_{i,j}^{n}+u_{i-1,j}^{n}}{\\Delta x^2}+\\frac{u_{i,j+1}^{n}-2 u_{i,j}^{n}+u_{i,j-1}^{n}}{\\Delta y^2}=f_{i,j}^{n}\\qquad (1)$$\n",
    "\n",
    "(o índice superior $n$ vai indicar a ordem de iteração quando chegarmos aos métodos iterativos, enquanto $i,j$ rotulam os pontos da grelha na direção $x,y$, respectivamente).  \n",
    "Resolvendo a equação (1) em ordem a $u_{i,j}^{n}$, temos:\n",
    "\n",
    "$$u_{i,j}^{n}=\\frac{(u_{i+1,j}^{n}+u_{i-1,j}^{n})\\Delta y^2+(u_{i,j+1}^{n}+u_{i,j-1}^{n})\\Delta x^2-f_{i,j}^{n}\\Delta x^2\\Delta y^2}{2(\\Delta x^2+\\Delta y^2)}$$\n",
    "\n",
    "No caso particular, mas comum, de $\\Delta x =\\Delta y \\equiv h$ temos a expressão mais simples:\n",
    "\n",
    "$$u_{i,j}^{n}=\\frac{u_{i+1,j}^{n}+u_{i-1,j}^{n} + u_{i,j+1}^{n}+u_{i,j-1}^{n}}{4}-f_{i,j}^{n}h^2.$$\n",
    "\n",
    "Ou seja, o novo valor é a média do valor dos quatro vizinhos (Laplace) mais a contribuição do termo fonte(Poisson).\n",
    "\n",
    "Temos também que considerar condições fronteira. Estas podem tomar várias formas. Condições de Dirichelet correspondem a fixar o valor de $u$ na fronteira. Condições de Neumann correspondem a fixar o valor da derivada normal para fora na fronteira (fisicamente, o fluxo). E condições mistas (Robin) correspondem a prescrever em todos os pontos da fronteira uma combinação linear (ou não-linear!) da forma:\n",
    "\n",
    "$$\\alpha_l u(x,y) + \\beta_l \\frac{\\partial u(x,y)}{\\partial x} = \\gamma_l(y)$$\n",
    "\n",
    "para o caso de uma fronteira com $x=\\text{const}$, e temos expressões análogas para as fronteiras com $y=\\text{const}$.\n",
    "\n",
    "O nosso sistema de equações pode ser escrito na forma geral de um produto de uma matriz de coeficientes a multiplicar pelo vector de incógnitas, que deve ser igual ao termo fonte, de acordo com a equação (1). Teremos então:\n",
    "\n",
    "$$ \\begin{bmatrix} a_{11} & \\cdots &  a_{1N}\\\\ \\vdots & \\ddots & \\vdots \\\\ a_{N1} & \\cdots &  a_{NN} \\end{bmatrix} \\times   \\left[ \\begin{array}{c} u_1  \\\\ \\vdots \\\\u_N \\end{array} \\right] =\\left[ \\begin{array}{cc} b_1 \\\\ \\vdots \\\\ b_N \\end{array} \\right] $$  \n",
    "onde a matriz $\\mathbf{A}$ dos coeficientes tem dimensões $N\\times N$, (onde $N=n_x\\times n_y$) é pentadiagonal e só tem elementos não nulos na diagonal principal, onde valem $-\\frac{2}{\\Delta x^2}- \\frac{2}{\\Delta y^2}$; na primeira sobrediagonal e na primeira subdiagonal, onde valem   $\\frac{1}{\\Delta x^2}$; e na $n_x$-ésima sobrediagonal e na $n_x$-ésima subdiagonal, onde valem $\\frac{1}{\\Delta y^2}.$ Por seu lado o vector dos termos independentes, $\\mathbf{b}$, tem como componentes $f_m,\\ m\\in {1,\\cdots,N}.$ (Isto é verdade para ordenamento por colunas primeiro; se fôr por linhas serão as  $n_y$-ésima sobre/sub-diagonais a ser não nulas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos iterativos\n",
    "\n",
    "Para problemas com poucos nodos da rede, podemos usar métodos directos para resolver o sistema de equações que nos dá $u_{i,j}^{n}$. Em 2D a matriz dos coeficientes (quando ordenamos os pontos seguindo ao longo de cada coluna em série, ou quando seguimos ao longo de cada linha em série!) é uma matriz por bandas. No caso de 1D seria tridiagonal, para a qual temos o (eficiente) método de Thomas. No caso de 2D também há métodos mais eficientes que o método geral. Mas à medida que a dimensão do problema cresce, i.é, $N=n_x \\times n_y$ é grande, temos que nos voltar para os métodos iterativos.  \n",
    "\n",
    "Vamos considerar os vários métodos, e algumas variações. Temos assim os métodos de Jacobi, Gauss-Seidel e SOR (*successive-over-relaxations* ou sobre-relaxações sucessivas). \n",
    "\n",
    "Ao ordenar os nodos para que as variáveis $u_{i,j}^{n}$ sejam coordenadas de um vector, podemos escolher fazê-lo de várias maneiras (na realidade, qualquer permutação dos nodos é correcta, mas uma ordenação que não seja sistemática não é nada inteligente!). As mais usadas são *column-wise* ou *row-wise*, ié, percorrer cada coluna da primeira à última linha ($n_x$-ésima) , começando na primeira coluna e acabando na última ($n_y$-ésima), ou percorrendo primeiro linhas, para todas as linhas, por ordem. A escolha é indiferente do ponto de vista de escrever o algoritmo ou até o código, mas não o é do ponto de vista do desempenho do programa ao correr! Isso tem a ver com o modo como cada linguagem de programação guarda valores de um **array** na memória. Mas não nos vamos preocupar com esse problema neste momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método de Jacobi\n",
    "Comecemos pelo método de Jacobi. Neste caso a actualização de $u_{i,j}^{n}$, ié, $u_{i,j}^{n+1}$, é feita exclusivamente à custa dos $u_{i,j}^{n}$, obtidos na iteração anterior:\n",
    "\n",
    "$\\begin{align}\n",
    "    u_{k}^{n+1} &= \\frac{1}{a_{kk}}\\left[ b_k - \\sum_{\\substack{l=1 \\\\ j\\neq i}}^{N} a_{kl}u_l^{n} \\right] \\tag{3.1}\\\\\n",
    "    u_{k}^{n+1} &= u_{k}^{n} + \\delta u_{k}^{n}\n",
    "\\tag{3.2}\\\\ \n",
    "    \\delta u_k &=\\frac{1}{a_{kk}} \\left[b_k-\\sum^{N}_{l=1}a_{kl}u^m_l\\right],\\ k=1,2,\\dots,N,\\ l=0,1,\\dots\n",
    "\\tag{3.3}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos exprimir este resultado numa forma matricial.\n",
    "$$ A =\\begin{bmatrix} a_{11} & 0 & \\cdots &  0 &0\\\\ 0 & 0 & a_{22} & \\cdots &  0\\\\ \\vdots & \\vdots &\\ddots & \\vdots & \\vdots \\\\ 0 & 0 &\\cdots & 0 & a_{NN} \\end{bmatrix} +\n",
    " \\begin{bmatrix} 0 & 0 & \\cdots & 0 &  0\\\\a_{21} & 0 & 0& \\cdots & 0 \\\\ \\vdots & \\vdots &\\ddots & \\vdots & \\vdots \\\\ a_{N1} & a_{N2} &\\cdots & a_{N,N-1} &  0 \\end{bmatrix} +\n",
    " \\begin{bmatrix} 0 & a_{12} & \\cdots & a_{1,N-1} &  a_{1N}\\\\0 & 0 & \\cdots & a_{2,N-1} & a_{2N}\\\\ \\vdots & \\vdots &\\ddots &  0&  a_{N-1,N} \\\\ 0 & 0 &\\cdots & 0 & 0 \\end{bmatrix}  = L + D + U$$\n",
    " Então podemos escrever $A\\mathbf{u}=\\mathbf{b}$ como $(D+L+U)\\mathbf{u}=\\mathbf{b}$ donde $D\\mathbf{u}=-(L+U)\\mathbf{u}+\\mathbf{b}$. Supondo que $D^{-1}$ existe e é dada por:\n",
    " $$ D^{-1} = \\begin{bmatrix} \\frac{1}{a_{11}} & 0 & \\cdots &  0 &0\\\\ 0 & 0 & \\frac{1}{a_{22}} & \\cdots &  0\\\\ \\vdots & \\vdots &\\ddots & \\vdots & \\vdots \\\\ 0 & 0 &\\cdots & 0 & \\frac{1}{a_{NN}} \\end{bmatrix}\n",
    " $$\n",
    " temos\n",
    " $$\\mathbf{u}=-D^{-1}(L+U)\\mathbf{u}+D^{-1}\\mathbf{b}.$$\n",
    " \n",
    " A iteração de Jacobi pode então ser escrita na forma matricial como:\n",
    " $$ \\mathbf{u}^{m+1}=-D^{-1}(L+U)\\mathbf{u}^{m}+D^{-1}\\mathbf{b}.\n",
    " $$\n",
    " Como as matrizes têm coeficientes constantes, podemos definir $T\\equiv -D^{-1}(L+U)$ e a iteração é simplesmente: $\\mathbf{u}^{m+1}= T\\mathbf{u}^{m}+D^{-1}\\mathbf{b}$. (Se as condições fronteira forem de Dirichelet, $\\mathbf{b}$ é constante e podemos também definir um $\\mathbf{c} \\equiv D^{-1}\\mathbf{b}$, vindo $\\mathbf{u}^{m+1}= T\\mathbf{u}^{m}+ \\mathbf{c}.$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método de Gauss-Seidel\n",
    "O método de Gauss-Seidel tira partido de dois factos: i) pode-se provar que para certas matrizes (e a dos coeficientes da equação de Laplace/Poisson está nesse lote!) cada actualização de um nodo leva o sistema globalmente para mais perto da solução; e ii) se seguirmos uma ordem de actualização regular (como a ordenação que resulta de percorrer cada coluna de seguida) os nodos já actualizados na presente iteração têm valores \"melhores\" que os da iteração anterior. O algoritmo pode então ser partido em duas somas, ficando na forma:\n",
    "\n",
    "$ \\begin{align}\n",
    "u_{k}^{n+1} =& \\frac{1}{a_{kk}}\\left[ b_k - \\sum_{l=1}^{k-1} a_{kl}u_l^{n+1} - \\sum_{l=k+1}^{N} a_{kl}u_l^{n}\\right] \\tag{3.4}\\\\\n",
    "=&u_{k}^{n} + \\frac{1}{a_{kk}}\\left[ b_k - \\sum_{l=1}^{k-1} a_{kl}u_l^{n+1} - \\sum_{l=k}^{N} a_{kl}u_l^{n}\\right] \\tag{3.5}\\\\\n",
    "=&u_{k}^{n} + \\delta_{k}^{n}.\\tag{3.6}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o método de Gauss-Seidel, tendo em conta que os valores já actualizados correspondem à parte superior do vector $\\mathbf{u}$, que é multiplicada pela matriz $L$, a forma matricial vem:\n",
    "$$(D+L)\\mathbf{u}^{m+1}= -U\\mathbf{u}^{m}+ \\mathbf{b},\n",
    "$$ ou\n",
    "$$ \\mathbf{u}^{m+1}=-(D+L)^{-1}U\\mathbf{u}^{m}+ (D+L)^{-1}\\mathbf{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método de SOR\n",
    "O método SOR procura melhorar a método de Gauss-Seidel, aumentando o tamanho da correção por um factor $\\omega$. O racional é que se em cada actualização estamos a aproximar-nos da solução, então \"esticar\" essa correção deve-nos levar mais depressa para a solução. Em geral, isso resulta. Mas nem sempre. Também podemos usar $\\omega<1$ para \"abrandar\" problemas que tendem a não convergir, e nesse caso o método chama-se de *sub-relaxações successivas*.  \n",
    "Note-se que se $\\omega=1$ recuperamos o método de Gauss-Seidel, e se $\\omega=0$ recuperamos o método de Jacobi.    \n",
    "Cada problema tem um $\\omega$ óptimo, mas que depende quer da equação, quer da geometria do domínio. Em geral é mais fácil obtê-lo por tentativas (frequentemente é à volta de $1.6$).\n",
    "$ \\begin{align}\n",
    "u_{k}^{n+1}=& (1-\\omega) u_{k}^{n} + \\omega \\delta_{k}^{n} \\tag{3.7}\\\\\n",
    "=& (1-\\omega) u_{k}^{n} + \\frac{\\omega}{a_{kk}}\\left[ b_k - \\sum_{l=1}^{k-1} a_{kl}u_l^{n+1} - \\sum_{l=k}^{N} a_{kl}u_l^{n}\\right]   \\tag{3.8}\\\\\n",
    "u_{k}^{n+1}=&(1-\\omega)u_{k}^{n} + \\frac{\\omega}{a_{kk}}\\left[ b_k - \\sum_{l=1}^{k-1} a_{kl}u_l^{n+1} - \\sum_{l=k+1}^{N} a_{kl}u_l^{n}\\right]\n",
    "\\tag{3.9}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note-se que no caso das equações de Poisson/Laplace é mais eficaz usar a equação directamente, já que a grande maioria dos coeficientes é núla. Assim escrevemos algo como:\n",
    "$\\begin{align}\n",
    "    &u_{k}^{m+1}=u_{k}^m+\\delta u_{k}\n",
    "\\tag{3.10}\\\\ \n",
    "    &\\delta u_{k}=\\frac{\\omega}{4}\n",
    "      \\left[u^{m+1}_{k-1}+u^{m+1}_{k+1}+u^{m}_{k-n_x}+u^{m}_{k+n_x}-4u^{m}_{i,j}-h^2\\cdot\n",
    "      f_{i,j}\\right]\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Definindo o resíduo a cada iteração como:\n",
    "\n",
    "$\n",
    "R_{k}=\\left[u^{m+1}_{k-1}+u^{m+1}_{k+1}+u^{m}_{k-n_x}+u^{m}_{k+n_x}-4u^{m}_{k}-h^2\\cdot\n",
    "f_{k}\\right]\n",
    "$\n",
    "podemos escrever para a equação de Poisson:\n",
    "\n",
    "$\n",
    "u_{k}^{m+1}=u_{k}^m+\\frac{\\omega}{4}R_{k}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a forma matricial fazemos:\n",
    "$$(D+ \\omega L)\\mathbf{u}= \\omega\\mathbf{b} - \\left[ \\omega U + (\\omega -1)D \\right]\\mathbf{u},\n",
    "$$\n",
    "pelo que a iteração se pode escrever como:\n",
    "$$ \\mathbf{u}^{m+1}=-(D+ \\omega L)^{-1}\\Big(\\omega\\mathbf{b} - \\big[ \\omega U + (\\omega -1)D \\big]\\mathbf{u}^{m} \\Big)\n",
    "$$\n",
    "\n",
    "No entanto, tendo em conta que $(D+\\omega L)$ é triangular, os elementos de $\\mathbf{u}^{m+1}$ podem ser calculados sequencialmente por substituição para a frente (forward substitution).\n",
    "\n",
    "\n",
    " $$u_i^{k + 1} = ( 1 − \\omega ) u_i^{k} + \\frac{\\omega}{a_{ii}}\\Big(b_i -\\sum_{j<i} a_{ij}u_j^{k+1} - \\sum_{j>i} a_{ij}u_j^{k} \\Big) ,\\qquad i = 1,2 \\ldots , N $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parâmetro de relaxação óptimo\n",
    "Num domínio rectangular com $n_x+1$, $n_y+1$ nodos (e o mesmo espaçamento em cada direcção), o valor óptimo teórico de $\\omega$ é dado por:\n",
    "\n",
    "$\\omega = \\frac{2}{1+\\sqrt{1-\\rho^2}},\n",
    "$\n",
    "\n",
    "onde:\n",
    "\n",
    "$\n",
    "\\rho = \\frac{1}{2}[\\cos(\\pi/n_x) + \\cos(\\pi(n_y)].$\n",
    "\n",
    "Se o domínio não fôr rectangular, há uma estimativa devida a Garabedian:\n",
    "\n",
    "$\\omega = \\frac{2}{1+3.014 h/\\sqrt{A}},\n",
    "$\n",
    "\n",
    "onde $h$ é o passo em ambas as direcções, e $A$ é a área do domínio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenação \"Red-black\"\n",
    "![red-black ordering](red-black.png)  \n",
    "Pontos abertos representam fronteira, ponto interiores são vermelhos ou pretos. Cada um tem apenas vizinhos da cor oposta! Assim na actualização dos valores em cada iteração, podemos actualizar todos os pontos vermelhos à custa dos pontos pretos da iteração anterior.  De seguida actualizamos todos os pontos pretos à custa apenas dos pontos vermelhos já calculados para essa iteração. E podemos fazer cada os procedimento em paralelo (ié, vectorizar pontos vermelhos e pontos pretos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-código para red-black\n",
    "\n",
    "# solução inicial u\n",
    "u = np.array[...];\n",
    " \n",
    "for k in range(len(numIterations)):\n",
    "    # pontos vermelhos\n",
    "    for j in enumerate(y[1:-1]):\n",
    "        for i = in enumerate(x[1:-1]):\n",
    "            if (mod((i + j)% 2) == 0)\n",
    "                u[i, j] = 1/4 * (u[i - 1, j] + u[i + 1, j] + u[i, j - 1] + u[i, j + 1] + h**2*f[i, j])\n",
    " \n",
    "    # pontos  pretos\n",
    "    for j in enumerate(y[1:-1]):\n",
    "        for i = in enumerate(x[1:-1]):\n",
    "            if (mod((i + j)% 2) == 1)\n",
    "                u[i, j] = 1/4 * (u[i - 1, j] + u[i + 1, j] + u[i, j - 1] + u[i, j + 1] + h**2*f[i, j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra forma é usar máscaras (masks), o que permite usar sub-arrays (à semelhança de slices). Ver, por exemplo, https://hplgit.github.io/fdm-book/doc/pub/book/pdf/fdm-book-4screen.pdf sec 3.6.14, para um exemplo do uso de slices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critério de paragem da iteração\n",
    "O critério de paragem deve ser mais apurado que um número prescrito máximo de iterações. Num problema podem ser de mais, noutro não serem suficientes. Podemos tomar uma medida numérica do erro como critério. \n",
    "  - absoluto:  $\\text{max}(\\delta u_{i,j})< \\epsilon_a$\n",
    "  - relativo:  $\\text{max}(\\delta u_{i,j}/u_{i,j})< \\epsilon_r$\n",
    "  - resíduo\n",
    "  - outros, como:\n",
    "     - $\\frac{1}{N}\\sum_i\\sum_j |\\delta u_{i,j}|< \\epsilon_a$ (N é o número total de incógnitas)\n",
    "     - $\\frac{1}{N}\\sum_i\\sum_j |\\delta u_{i,j}/u_{i,j}| < \\epsilon_r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo de critério de paragem por erro relativo\n",
    "reltol=1.0e-3\n",
    "\n",
    "omega = 1.5\n",
    "iteration = 0\n",
    "rel_res=1.0\n",
    "\n",
    "# solução por SOR\n",
    "tic=time.time()\n",
    "while (rel_res > reltol):\n",
    "    dTmax=0.0\n",
    "    for j in range(1,ny+1):\n",
    "        for i in range(1, nx + 1):\n",
    "            R = (T[j,i-1]+T[j-1,i]+T[j,i+1]+T[j+1,i]-4.0*T[j,i])\n",
    "            dT = 0.25*omega*R\n",
    "            T[j,i]+=dT\n",
    "            dTmax=np.max([np.abs(dT),dTmax])\n",
    "        \n",
    "    rel_res=dTmax/np.max(np.abs(T))\n",
    "    iteration+=1\n",
    "    \n",
    "toc=time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
